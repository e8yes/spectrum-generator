{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pretrained Masked Language Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30522"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertForMaskedLM\n",
    "import torch\n",
    "\n",
    "#MODEL_TYPE = \"prajjwal1/bert-tiny\"\n",
    "MODEL_TYPE = \"bert-base-uncased\"\n",
    "tokenizer = BertTokenizer.from_pretrained(MODEL_TYPE)\n",
    "\n",
    "tokenizer.vocab_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [\n",
    "    (\"After Abraham Lincoln won the November 1860 presidential \"\n",
    "     \"election on an anti-slavery platform, an initial seven \"\n",
    "     \"slave states declared their secession from the country \"\n",
    "     \"to form the Confederacy. War broke out in April 1861 \"\n",
    "     \"when secessionist forces attacked Fort Sumter in South \"\n",
    "     \"Carolina, just over a month after Lincoln's \"\n",
    "     \"[MASK].\"),\n",
    "    (\"In response to Lincoln's election, seven Southern states \"\n",
    "     \"seceded from the Union and formed the Confederate States \"\n",
    "     \"of America. These states were South Carolina, Mississippi, \"\n",
    "     \"Florida, Alabama, Georgia, Louisiana, and Texas. The \"\n",
    "     \"secession of these states was a direct challenge to the \"\n",
    "     \"authority of the federal government and set the stage for \"\n",
    "     \"the Civil [MASK].\"),\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transformers.tokenization_utils_base.BatchEncoding"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = tokenizer(texts, \n",
    "                   padding=True,\n",
    "                   return_tensors='pt')\n",
    "type(inputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  101,  2044,  8181,  5367,  2180,  1996,  2281,  7313,  4883,  2602,\n",
       "          2006,  2019,  3424,  1011,  8864,  4132,  1010,  2019,  3988,  2698,\n",
       "          6658,  2163,  4161,  2037, 22965,  2013,  1996,  2406,  2000,  2433,\n",
       "          1996, 18179,  1012,  2162,  3631,  2041,  1999,  2258,  6863,  2043,\n",
       "         22965,  2923,  2749,  4457,  3481,  7680,  3334,  1999,  2148,  3792,\n",
       "          1010,  2074,  2058,  1037,  3204,  2044,  5367,  1005,  1055,   103,\n",
       "          1012,   102,     0,     0,     0,     0,     0,     0,     0,     0],\n",
       "        [  101,  1999,  3433,  2000,  5367,  1005,  1055,  2602,  1010,  2698,\n",
       "          2670,  2163, 10819, 19082,  2013,  1996,  2586,  1998,  2719,  1996,\n",
       "          8055,  2163,  1997,  2637,  1012,  2122,  2163,  2020,  2148,  3792,\n",
       "          1010,  5900,  1010,  3516,  1010,  6041,  1010,  4108,  1010,  5773,\n",
       "          1010,  1998,  3146,  1012,  1996, 22965,  1997,  2122,  2163,  2001,\n",
       "          1037,  3622,  4119,  2000,  1996,  3691,  1997,  1996,  2976,  2231,\n",
       "          1998,  2275,  1996,  2754,  2005,  1996,  2942,   103,  1012,   102]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs[\"input_ids\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(inputs[\"input_ids\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs['labels'] = inputs.input_ids.detach().clone()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101,  2044,  8181,  5367,  2180,  1996,  2281,  7313,  4883,  2602,\n",
       "          2006,  2019,  3424,  1011,  8864,  4132,  1010,  2019,  3988,  2698,\n",
       "          6658,  2163,  4161,  2037, 22965,  2013,  1996,  2406,  2000,  2433,\n",
       "          1996, 18179,  1012,  2162,  3631,  2041,  1999,  2258,  6863,  2043,\n",
       "         22965,  2923,  2749,  4457,  3481,  7680,  3334,  1999,  2148,  3792,\n",
       "          1010,  2074,  2058,  1037,  3204,  2044,  5367,  1005,  1055,   103,\n",
       "          1012,   102,     0,     0,     0,     0,     0,     0,     0,     0],\n",
       "        [  101,  1999,  3433,  2000,  5367,  1005,  1055,  2602,  1010,  2698,\n",
       "          2670,  2163, 10819, 19082,  2013,  1996,  2586,  1998,  2719,  1996,\n",
       "          8055,  2163,  1997,  2637,  1012,  2122,  2163,  2020,  2148,  3792,\n",
       "          1010,  5900,  1010,  3516,  1010,  6041,  1010,  4108,  1010,  5773,\n",
       "          1010,  1998,  3146,  1012,  1996, 22965,  1997,  2122,  2163,  2001,\n",
       "          1037,  3622,  4119,  2000,  1996,  3691,  1997,  1996,  2976,  2231,\n",
       "          1998,  2275,  1996,  2754,  2005,  1996,  2942,   103,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 70])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs[\"input_ids\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertModel\n",
    "from transformers import BertForMaskedLM\n",
    "\n",
    "model = BertForMaskedLM.from_pretrained(MODEL_TYPE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model(\n",
    "    input_ids=inputs[\"input_ids\"],\n",
    "    token_type_ids=inputs[\"token_type_ids\"],\n",
    "    attention_mask=inputs[\"attention_mask\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MaskedLMOutput(loss=None, logits=tensor([[[ -8.2426,  -8.2028,  -8.2557,  ...,  -7.2883,  -7.3752,  -5.1033],\n",
       "         [-12.1989, -12.0338, -12.2798,  ..., -11.5445, -11.1747,  -8.9771],\n",
       "         [ -7.0761,  -7.1125,  -6.6490,  ...,  -6.5038,  -7.1784,  -5.4737],\n",
       "         ...,\n",
       "         [ -6.3599,  -6.8373,  -6.5935,  ...,  -4.8487,  -6.6077,  -6.9051],\n",
       "         [ -3.3518,  -4.0345,  -3.3448,  ...,  -2.6487,  -4.2840,  -4.2557],\n",
       "         [ -4.1612,  -4.8025,  -4.1519,  ...,  -3.4086,  -4.8660,  -5.3375]],\n",
       "\n",
       "        [[ -7.6152,  -7.6263,  -7.6300,  ...,  -6.8500,  -6.8573,  -4.5814],\n",
       "         [-17.0938, -17.0038, -17.3263,  ..., -14.5825, -14.6042, -12.8379],\n",
       "         [ -5.0147,  -4.7896,  -5.4301,  ...,  -4.7335,  -5.2917,  -3.1833],\n",
       "         ...,\n",
       "         [ -2.9033,  -2.5517,  -3.0579,  ...,  -0.9628,  -2.7572,  -3.4291],\n",
       "         [-14.2287, -14.2686, -14.2860,  ..., -11.8868, -11.9608,  -9.9601],\n",
       "         [-10.1814, -10.7392, -10.2036,  ...,  -9.8099,  -7.6379,  -8.2945]]],\n",
       "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['logits'])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 70, 128])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.last_hidden_state.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 128])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.pooler_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_texts = [\n",
    "    (\"Abraham Lincoln was the 16th President of the United States, serving from \"\n",
    "     \"1861 until his assassination in 1865. He is widely considered to be one \"\n",
    "     \"of the most important and influential figures in American history, \"\n",
    "     \"particularly for his role in leading the country through the Civil War \"\n",
    "     \"and for his efforts to abolish slavery.\"),\n",
    "     (\"Lincoln was born on February 12, \"\n",
    "     \"1809, in Hodgenville, Kentucky. He grew up in poverty and received only a \"\n",
    "     \"limited formal education. Nevertheless, he taught himself law and became \"\n",
    "     \"a successful lawyer before entering politics. He served in the Illinois \"\n",
    "     \"legislature and in the U.S. House of Representatives before being elected \"\n",
    "     \"president in 1860.\"),\n",
    "]\n",
    "\n",
    "test_inputs = tokenizer(test_texts,\n",
    "                        padding=True,\n",
    "                        return_tensors='pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 69])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_inputs[\"input_ids\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 69, 128])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_output = model(\n",
    "    input_ids=test_inputs[\"input_ids\"],\n",
    "    token_type_ids=test_inputs[\"token_type_ids\"],\n",
    "    attention_mask=test_inputs[\"attention_mask\"])\n",
    "\n",
    "test_output.last_hidden_state.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "User Profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 5])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "user_profiles = torch.Tensor([\n",
    "    [0.1, 0.2, 0.3, 0.4, 0.5],\n",
    "    [1.0, 2.0, 3.0, 4.0, 5.0]])\n",
    "\n",
    "user_profiles.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict Masked Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.1000,  0.2000,  0.3000,  ..., -0.9320, -0.6556,  1.8571],\n",
       "         [ 0.1000,  0.2000,  0.3000,  ..., -1.7244, -0.7812,  0.5787],\n",
       "         [ 0.1000,  0.2000,  0.3000,  ..., -2.1885, -0.9960,  2.9772],\n",
       "         ...,\n",
       "         [ 0.1000,  0.2000,  0.3000,  ..., -1.0744, -0.0773,  1.9667],\n",
       "         [ 0.1000,  0.2000,  0.3000,  ..., -0.7104, -0.1538,  1.6433],\n",
       "         [ 0.1000,  0.2000,  0.3000,  ..., -0.7003, -0.2023,  1.6985]],\n",
       "\n",
       "        [[ 1.0000,  2.0000,  3.0000,  ..., -0.5218, -1.3571,  2.4143],\n",
       "         [ 1.0000,  2.0000,  3.0000,  ..., -2.1451, -0.7536,  1.1829],\n",
       "         [ 1.0000,  2.0000,  3.0000,  ..., -1.7277, -1.7523,  2.3260],\n",
       "         ...,\n",
       "         [ 1.0000,  2.0000,  3.0000,  ..., -1.0819, -0.8957,  0.4729],\n",
       "         [ 1.0000,  2.0000,  3.0000,  ..., -0.7759, -0.8671,  0.5607],\n",
       "         [ 1.0000,  2.0000,  3.0000,  ..., -1.1317, -0.9062,  1.0917]]],\n",
       "       grad_fn=<CatBackward0>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "batch_size = output.last_hidden_state.size()[0]\n",
    "sequence_len = output.last_hidden_state.size()[1]\n",
    "\n",
    "user_profiles = torch.reshape(\n",
    "    input=user_profiles, shape=(batch_size, 1, 5))\n",
    "user_profiles_cloned = user_profiles.repeat(\n",
    "    repeats=(1, sequence_len, 1))\n",
    "\n",
    "\n",
    "all_features = torch.concatenate(\n",
    "    (user_profiles_cloned, output.last_hidden_state), dim=2)\n",
    "\n",
    "all_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0159, 0.0175, 0.0113,  ..., 0.0113, 0.0178, 0.0116],\n",
       "         [0.0213, 0.0075, 0.0087,  ..., 0.0191, 0.0092, 0.0125],\n",
       "         [0.0161, 0.0112, 0.0111,  ..., 0.0138, 0.0103, 0.0126],\n",
       "         ...,\n",
       "         [0.0175, 0.0066, 0.0173,  ..., 0.0178, 0.0116, 0.0123],\n",
       "         [0.0174, 0.0079, 0.0169,  ..., 0.0177, 0.0117, 0.0115],\n",
       "         [0.0152, 0.0078, 0.0144,  ..., 0.0173, 0.0101, 0.0121]],\n",
       "\n",
       "        [[0.0188, 0.0187, 0.0110,  ..., 0.0093, 0.0235, 0.0112],\n",
       "         [0.0124, 0.0074, 0.0237,  ..., 0.0154, 0.0083, 0.0079],\n",
       "         [0.0239, 0.0160, 0.0136,  ..., 0.0063, 0.0181, 0.0154],\n",
       "         ...,\n",
       "         [0.0220, 0.0062, 0.0179,  ..., 0.0199, 0.0181, 0.0095],\n",
       "         [0.0134, 0.0088, 0.0132,  ..., 0.0263, 0.0077, 0.0155],\n",
       "         [0.0164, 0.0072, 0.0188,  ..., 0.0128, 0.0102, 0.0248]]],\n",
       "       grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear = torch.nn.Linear(\n",
    "    in_features=128 + 5, out_features=tokenizer.vocab_size)\n",
    "softmax = torch.nn.Softmax(dim=1)\n",
    "\n",
    "h_transformed = linear(all_features)\n",
    "preds = softmax(h_transformed)\n",
    "\n",
    "preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 70, 30522])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.shape\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
