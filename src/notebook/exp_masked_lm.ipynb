{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pretrained Masked Language Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-29 20:32:26.921875: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-29 20:32:27.001244: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-03-29 20:32:27.001257: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-03-29 20:32:27.566320: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-29 20:32:27.566363: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-29 20:32:27.566368: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertForMaskedLM\n",
    "import torch\n",
    "\n",
    "# prajjwal1/bert-tiny\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [\n",
    "    (\"After Abraham Lincoln won the November 1860 presidential \"\n",
    "     \"election on an anti-slavery platform, an initial seven \"\n",
    "     \"slave states declared their secession from the country \"\n",
    "     \"to form the Confederacy. War broke out in April 1861 \"\n",
    "     \"when secessionist forces attacked Fort Sumter in South \"\n",
    "     \"Carolina, just over a month after Lincoln's \"\n",
    "     \"inauguration.\"),\n",
    "    (\"In response to Lincoln's election, seven Southern states \"\n",
    "     \"seceded from the Union and formed the Confederate States \"\n",
    "     \"of America. These states were South Carolina, Mississippi, \"\n",
    "     \"Florida, Alabama, Georgia, Louisiana, and Texas. The \"\n",
    "     \"secession of these states was a direct challenge to the \"\n",
    "     \"authority of the federal government and set the stage for \"\n",
    "     \"the Civil War.\")\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(texts, padding=True, return_tensors='pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101,  2044,  8181,  5367,  2180,  1996,  2281,  7313,  4883,  2602,\n",
       "          2006,  2019,  3424,  1011,  8864,  4132,  1010,  2019,  3988,  2698,\n",
       "          6658,  2163,  4161,  2037, 22965,  2013,  1996,  2406,  2000,  2433,\n",
       "          1996, 18179,  1012,  2162,  3631,  2041,  1999,  2258,  6863,  2043,\n",
       "         22965,  2923,  2749,  4457,  3481,  7680,  3334,  1999,  2148,  3792,\n",
       "          1010,  2074,  2058,  1037,  3204,  2044,  5367,  1005,  1055, 17331,\n",
       "          1012,   102,     0,     0,     0,     0,     0,     0,     0,     0],\n",
       "        [  101,  1999,  3433,  2000,  5367,  1005,  1055,  2602,  1010,  2698,\n",
       "          2670,  2163, 10819, 19082,  2013,  1996,  2586,  1998,  2719,  1996,\n",
       "          8055,  2163,  1997,  2637,  1012,  2122,  2163,  2020,  2148,  3792,\n",
       "          1010,  5900,  1010,  3516,  1010,  6041,  1010,  4108,  1010,  5773,\n",
       "          1010,  1998,  3146,  1012,  1996, 22965,  1997,  2122,  2163,  2001,\n",
       "          1037,  3622,  4119,  2000,  1996,  3691,  1997,  1996,  2976,  2231,\n",
       "          1998,  2275,  1996,  2754,  2005,  1996,  2942,  2162,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs['labels'] = inputs.input_ids.detach().clone()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101,  2044,  8181,  5367,  2180,  1996,  2281,  7313,  4883,  2602,\n",
       "          2006,  2019,  3424,  1011,  8864,  4132,  1010,  2019,  3988,  2698,\n",
       "          6658,  2163,  4161,  2037, 22965,  2013,  1996,  2406,  2000,  2433,\n",
       "          1996, 18179,  1012,  2162,  3631,  2041,  1999,  2258,  6863,  2043,\n",
       "         22965,  2923,  2749,  4457,  3481,  7680,  3334,  1999,  2148,  3792,\n",
       "          1010,  2074,  2058,  1037,  3204,  2044,  5367,  1005,  1055, 17331,\n",
       "          1012,   102,     0,     0,     0,     0,     0,     0,     0,     0],\n",
       "        [  101,  1999,  3433,  2000,  5367,  1005,  1055,  2602,  1010,  2698,\n",
       "          2670,  2163, 10819, 19082,  2013,  1996,  2586,  1998,  2719,  1996,\n",
       "          8055,  2163,  1997,  2637,  1012,  2122,  2163,  2020,  2148,  3792,\n",
       "          1010,  5900,  1010,  3516,  1010,  6041,  1010,  4108,  1010,  5773,\n",
       "          1010,  1998,  3146,  1012,  1996, 22965,  1997,  2122,  2163,  2001,\n",
       "          1037,  3622,  4119,  2000,  1996,  3691,  1997,  1996,  2976,  2231,\n",
       "          1998,  2275,  1996,  2754,  2005,  1996,  2942,  2162,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]), 'labels': tensor([[  101,  2044,  8181,  5367,  2180,  1996,  2281,  7313,  4883,  2602,\n",
       "          2006,  2019,  3424,  1011,  8864,  4132,  1010,  2019,  3988,  2698,\n",
       "          6658,  2163,  4161,  2037, 22965,  2013,  1996,  2406,  2000,  2433,\n",
       "          1996, 18179,  1012,  2162,  3631,  2041,  1999,  2258,  6863,  2043,\n",
       "         22965,  2923,  2749,  4457,  3481,  7680,  3334,  1999,  2148,  3792,\n",
       "          1010,  2074,  2058,  1037,  3204,  2044,  5367,  1005,  1055, 17331,\n",
       "          1012,   102,     0,     0,     0,     0,     0,     0,     0,     0],\n",
       "        [  101,  1999,  3433,  2000,  5367,  1005,  1055,  2602,  1010,  2698,\n",
       "          2670,  2163, 10819, 19082,  2013,  1996,  2586,  1998,  2719,  1996,\n",
       "          8055,  2163,  1997,  2637,  1012,  2122,  2163,  2020,  2148,  3792,\n",
       "          1010,  5900,  1010,  3516,  1010,  6041,  1010,  4108,  1010,  5773,\n",
       "          1010,  1998,  3146,  1012,  1996, 22965,  1997,  2122,  2163,  2001,\n",
       "          1037,  3622,  4119,  2000,  1996,  3691,  1997,  1996,  2976,  2231,\n",
       "          1998,  2275,  1996,  2754,  2005,  1996,  2942,  2162,  1012,   102]])}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False,  True,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False,  True, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False,  True,  True,\n",
       "         False, False, False,  True, False, False,  True, False, False, False],\n",
       "        [False, False, False, False, False,  True, False, False, False,  True,\n",
       "         False, False, False, False,  True, False, False,  True, False, False,\n",
       "          True, False, False, False,  True, False, False, False, False,  True,\n",
       "         False, False,  True, False, False,  True, False, False, False, False,\n",
       "         False, False, False, False,  True, False, False,  True, False, False,\n",
       "         False, False, False, False, False, False,  True, False, False, False,\n",
       "         False, False, False, False, False, False,  True, False, False, False]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand = torch.rand(inputs.input_ids.shape)\n",
    "mask_arr = (rand < 0.15) * (inputs.input_ids != 101) * (inputs.input_ids != 102)\n",
    "mask_arr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 70])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs[\"input_ids\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertModel\n",
    "\n",
    "model = BertModel.from_pretrained(\"bert-base-uncased\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model(\n",
    "    input_ids=inputs[\"input_ids\"],\n",
    "    token_type_ids=inputs[\"token_type_ids\"],\n",
    "    attention_mask=inputs[\"attention_mask\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 70, 768])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.last_hidden_state.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 768])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.pooler_output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "User Profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 5])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "user_profiles = torch.Tensor([\n",
    "    [0.1, 0.2, 0.3, 0.4, 0.5],\n",
    "    [1.0, 2.0, 3.0, 4.0, 5.0]])\n",
    "\n",
    "user_profiles.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict Masked Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.1000,  0.2000,  0.3000,  ..., -0.5229,  0.0727,  0.4822],\n",
       "         [ 0.1000,  0.2000,  0.3000,  ..., -0.6454, -0.1276,  0.3828],\n",
       "         [ 0.1000,  0.2000,  0.3000,  ..., -0.3775, -0.0720,  0.7561],\n",
       "         ...,\n",
       "         [ 0.1000,  0.2000,  0.3000,  ...,  0.0268, -0.2146,  0.1057],\n",
       "         [ 0.1000,  0.2000,  0.3000,  ...,  0.0059, -0.2434,  0.3223],\n",
       "         [ 0.1000,  0.2000,  0.3000,  ..., -0.0615, -0.1829,  0.4679]],\n",
       "\n",
       "        [[ 1.0000,  2.0000,  3.0000,  ..., -0.3774,  0.0676,  0.3794],\n",
       "         [ 1.0000,  2.0000,  3.0000,  ..., -0.4656,  0.1010,  0.4625],\n",
       "         [ 1.0000,  2.0000,  3.0000,  ..., -0.6897, -0.6790,  0.2936],\n",
       "         ...,\n",
       "         [ 1.0000,  2.0000,  3.0000,  ..., -1.0303, -0.0412,  0.7372],\n",
       "         [ 1.0000,  2.0000,  3.0000,  ...,  0.2470, -0.4527, -0.2162],\n",
       "         [ 1.0000,  2.0000,  3.0000,  ..., -0.3900, -0.5209,  0.2052]]],\n",
       "       grad_fn=<CatBackward0>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "batch_size = output.last_hidden_state.size()[0]\n",
    "sequence_len = output.last_hidden_state.size()[1]\n",
    "\n",
    "user_profiles = torch.reshape(\n",
    "    input=user_profiles, shape=(batch_size, 1, 5))\n",
    "user_profiles_cloned = user_profiles.repeat(\n",
    "    repeats=(1, sequence_len, 1))\n",
    "\n",
    "\n",
    "all_features = torch.concatenate(\n",
    "    (user_profiles_cloned, output.last_hidden_state), dim=2)\n",
    "\n",
    "all_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0126, 0.0148, 0.0228,  ..., 0.0140, 0.0146, 0.0186],\n",
       "         [0.0124, 0.0084, 0.0138,  ..., 0.0183, 0.0210, 0.0225],\n",
       "         [0.0112, 0.0236, 0.0134,  ..., 0.0158, 0.0187, 0.0153],\n",
       "         ...,\n",
       "         [0.0176, 0.0135, 0.0140,  ..., 0.0164, 0.0139, 0.0120],\n",
       "         [0.0158, 0.0128, 0.0136,  ..., 0.0148, 0.0140, 0.0132],\n",
       "         [0.0161, 0.0122, 0.0130,  ..., 0.0145, 0.0139, 0.0137]],\n",
       "\n",
       "        [[0.0138, 0.0142, 0.0238,  ..., 0.0154, 0.0198, 0.0195],\n",
       "         [0.0101, 0.0096, 0.0156,  ..., 0.0142, 0.0152, 0.0186],\n",
       "         [0.0081, 0.0079, 0.0133,  ..., 0.0184, 0.0141, 0.0150],\n",
       "         ...,\n",
       "         [0.0144, 0.0111, 0.0134,  ..., 0.0167, 0.0176, 0.0181],\n",
       "         [0.0202, 0.0094, 0.0128,  ..., 0.0090, 0.0120, 0.0117],\n",
       "         [0.0076, 0.0144, 0.0108,  ..., 0.0069, 0.0124, 0.0127]]],\n",
       "       grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear = torch.nn.Linear(\n",
    "    in_features=768 + 5, out_features=tokenizer.vocab_size)\n",
    "softmax = torch.nn.Softmax(dim=1)\n",
    "\n",
    "h_transformed = linear(all_features)\n",
    "preds = softmax(h_transformed)\n",
    "\n",
    "preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 70, 30522])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.shape\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
